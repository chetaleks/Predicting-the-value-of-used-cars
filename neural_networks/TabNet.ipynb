{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch.multiprocessing as mp\nmp.set_start_method('spawn', force=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:21:43.616310Z","iopub.execute_input":"2025-06-15T08:21:43.616504Z","iopub.status.idle":"2025-06-15T08:21:47.878221Z","shell.execute_reply.started":"2025-06-15T08:21:43.616488Z","shell.execute_reply":"2025-06-15T08:21:47.877470Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Предсказание цены автомобиля при помощи нейронной сети\n\n**В этом ноутбуке мы последовательно:**\n- Установим и импортируем нужные библиотеки\n- Очистим данные и добавим новые информативные признаки\n- Подготовим выборки, закодируем и масштабируем признаки\n- Построим нейросетевую модель\n\n---","metadata":{}},{"cell_type":"markdown","source":"## 1. Установка и импорт","metadata":{}},{"cell_type":"code","source":"import pandas as pd, numpy as np, math, joblib, gc, warnings, os, random, json, pickle, time\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.linear_model import Ridge\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom tqdm.notebook import tqdm, trange\nimport matplotlib.pyplot as plt\n\nwarnings.filterwarnings(\"ignore\")\n\n# Импортируем библиотеки, фиксируем сиды и выбираем устройство.\nSEED = 42\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntqdm.pandas()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T13:28:54.881357Z","iopub.execute_input":"2025-06-15T13:28:54.881645Z","iopub.status.idle":"2025-06-15T13:28:54.889030Z","shell.execute_reply.started":"2025-06-15T13:28:54.881624Z","shell.execute_reply":"2025-06-15T13:28:54.888463Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":" ## 2. Загрузка данных","metadata":{}},{"cell_type":"code","source":"CARS_FILE_ID = '1liFEe1-yFISPSpRSvbv1wIH_avYNGmBI'\nRANDOM_STATE = 42\n\nrandom.seed(RANDOM_STATE)\nnp.random.seed(RANDOM_STATE)\n\n!gdown --id {CARS_FILE_ID}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:21:56.583981Z","iopub.execute_input":"2025-06-15T08:21:56.584548Z","iopub.status.idle":"2025-06-15T08:22:13.779930Z","shell.execute_reply.started":"2025-06-15T08:21:56.584527Z","shell.execute_reply":"2025-06-15T08:22:13.779187Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1liFEe1-yFISPSpRSvbv1wIH_avYNGmBI\nFrom (redirected): https://drive.google.com/uc?id=1liFEe1-yFISPSpRSvbv1wIH_avYNGmBI&confirm=t&uuid=ef7d9071-48c0-4452-97bf-0e700061bde3\nTo: /kaggle/working/dataset.csv\n100%|██████████████████████████████████████| 1.01G/1.01G [00:12<00:00, 82.4MB/s]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def mem_usage(df):\n    return f\"{df.memory_usage(deep=True).sum()/1024**2:.1f} MB\"\n\n\ndf = pd.read_csv(\"dataset.csv\", low_memory=False)\nprint(f\"RAW shape        : {df.shape}, mem: {mem_usage(df)}\")\n\nprint(\"\\nHead:\")\ndisplay(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:22:13.781344Z","iopub.execute_input":"2025-06-15T08:22:13.781567Z","iopub.status.idle":"2025-06-15T08:22:29.249466Z","shell.execute_reply.started":"2025-06-15T08:22:13.781546Z","shell.execute_reply":"2025-06-15T08:22:29.248811Z"}},"outputs":[{"name":"stdout","text":"RAW shape        : (604047, 24), mem: 1458.8 MB\n\nHead:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   production_year  mileage     condition  owners_number pts_original  \\\n0             2020    31000  CONDITION_OK              0          NaN   \n1             2017    96000  CONDITION_OK              0          NaN   \n2             2019    42500  CONDITION_OK              1         True   \n3             2013   130000  CONDITION_OK              2         True   \n4             2009    47800  CONDITION_OK              4         True   \n\n   horse_power accidents_resolution           region seller_type   brand  ...  \\\n0        170.0                   OK         Оренбург  COMMERCIAL  Abarth  ...   \n1        170.0                   OK         Оренбург  COMMERCIAL  Abarth  ...   \n2        179.0                   OK  Санкт-Петербург     PRIVATE  Abarth  ...   \n3        160.0                   OK           Москва     PRIVATE  Abarth  ...   \n4        135.0                   OK           Москва     PRIVATE  Abarth  ...   \n\n  engine_displacement engine_power  fuel_rate steering_wheel    price  \\\n0              1368.0        170.0        6.6           LEFT  1900000   \n1              1368.0        170.0        6.4           LEFT  2300000   \n2              1368.0        180.0        5.8           LEFT  2895000   \n3              1368.0        160.0        5.4           LEFT  1750000   \n4              1368.0        135.0        6.5           LEFT  2000000   \n\n   price_segment                                               tags  \\\n0         MEDIUM  allowed_for_credit;auction_call_free_report;au...   \n1         MEDIUM  allowed_for_credit;auction_call_free_report;au...   \n2         MEDIUM  allowed_for_credit;auction_call_free_report;au...   \n3         MEDIUM  allowed_for_credit;auction_call_free_report;av...   \n4         MEDIUM  allowed_for_credit;auction_call_free_report;au...   \n\n  auto_class                                          equipment  \\\n0          S                           sport-suspension;seats-2   \n1          S                                            seats-2   \n2          A                                            seats-4   \n3          A  automatic-lighting-control;voice-recognition;l...   \n4          A  leather-gear-stick;seats-4;apple-carplay;usb;a...   \n\n  complectation_available_options  \n0                             NaN  \n1                             NaN  \n2                             NaN  \n3                             NaN  \n4                             NaN  \n\n[5 rows x 24 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>production_year</th>\n      <th>mileage</th>\n      <th>condition</th>\n      <th>owners_number</th>\n      <th>pts_original</th>\n      <th>horse_power</th>\n      <th>accidents_resolution</th>\n      <th>region</th>\n      <th>seller_type</th>\n      <th>brand</th>\n      <th>...</th>\n      <th>engine_displacement</th>\n      <th>engine_power</th>\n      <th>fuel_rate</th>\n      <th>steering_wheel</th>\n      <th>price</th>\n      <th>price_segment</th>\n      <th>tags</th>\n      <th>auto_class</th>\n      <th>equipment</th>\n      <th>complectation_available_options</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020</td>\n      <td>31000</td>\n      <td>CONDITION_OK</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>170.0</td>\n      <td>OK</td>\n      <td>Оренбург</td>\n      <td>COMMERCIAL</td>\n      <td>Abarth</td>\n      <td>...</td>\n      <td>1368.0</td>\n      <td>170.0</td>\n      <td>6.6</td>\n      <td>LEFT</td>\n      <td>1900000</td>\n      <td>MEDIUM</td>\n      <td>allowed_for_credit;auction_call_free_report;au...</td>\n      <td>S</td>\n      <td>sport-suspension;seats-2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017</td>\n      <td>96000</td>\n      <td>CONDITION_OK</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>170.0</td>\n      <td>OK</td>\n      <td>Оренбург</td>\n      <td>COMMERCIAL</td>\n      <td>Abarth</td>\n      <td>...</td>\n      <td>1368.0</td>\n      <td>170.0</td>\n      <td>6.4</td>\n      <td>LEFT</td>\n      <td>2300000</td>\n      <td>MEDIUM</td>\n      <td>allowed_for_credit;auction_call_free_report;au...</td>\n      <td>S</td>\n      <td>seats-2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019</td>\n      <td>42500</td>\n      <td>CONDITION_OK</td>\n      <td>1</td>\n      <td>True</td>\n      <td>179.0</td>\n      <td>OK</td>\n      <td>Санкт-Петербург</td>\n      <td>PRIVATE</td>\n      <td>Abarth</td>\n      <td>...</td>\n      <td>1368.0</td>\n      <td>180.0</td>\n      <td>5.8</td>\n      <td>LEFT</td>\n      <td>2895000</td>\n      <td>MEDIUM</td>\n      <td>allowed_for_credit;auction_call_free_report;au...</td>\n      <td>A</td>\n      <td>seats-4</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2013</td>\n      <td>130000</td>\n      <td>CONDITION_OK</td>\n      <td>2</td>\n      <td>True</td>\n      <td>160.0</td>\n      <td>OK</td>\n      <td>Москва</td>\n      <td>PRIVATE</td>\n      <td>Abarth</td>\n      <td>...</td>\n      <td>1368.0</td>\n      <td>160.0</td>\n      <td>5.4</td>\n      <td>LEFT</td>\n      <td>1750000</td>\n      <td>MEDIUM</td>\n      <td>allowed_for_credit;auction_call_free_report;av...</td>\n      <td>A</td>\n      <td>automatic-lighting-control;voice-recognition;l...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009</td>\n      <td>47800</td>\n      <td>CONDITION_OK</td>\n      <td>4</td>\n      <td>True</td>\n      <td>135.0</td>\n      <td>OK</td>\n      <td>Москва</td>\n      <td>PRIVATE</td>\n      <td>Abarth</td>\n      <td>...</td>\n      <td>1368.0</td>\n      <td>135.0</td>\n      <td>6.5</td>\n      <td>LEFT</td>\n      <td>2000000</td>\n      <td>MEDIUM</td>\n      <td>allowed_for_credit;auction_call_free_report;au...</td>\n      <td>A</td>\n      <td>leather-gear-stick;seats-4;apple-carplay;usb;a...</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## 3. Предобработка и признаки","metadata":{}},{"cell_type":"code","source":"# АНОМАЛИЯ\ndf.drop(210905, inplace=True)\n\ndf[\"fuel_rate\"].fillna(df[\"fuel_rate\"].median(), inplace=True)\ndf[\"pts_original\"].fillna(True, inplace=True)\ndf[\"accidents_resolution\"].fillna(\"OK\", inplace=True)\ndf[\"auto_class\"].fillna(\"NOT SPECIFIED\", inplace=True)\ndf.drop(\"horse_power\", axis=1, inplace=True)\n\n\ndef optimize_types(d):\n    for col in d.select_dtypes(include=[\"int64\"]).columns:\n        d[col] = pd.to_numeric(d[col], downcast=\"integer\")\n    for col in d.select_dtypes(include=[\"float64\"]).columns:\n        d[col] = pd.to_numeric(d[col], downcast=\"float\")\n    return d\n\n\ndf = optimize_types(df)\nprint(f\"After dtype optimisation mem: {mem_usage(df)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:22:29.250166Z","iopub.execute_input":"2025-06-15T08:22:29.250402Z","iopub.status.idle":"2025-06-15T08:22:31.130637Z","shell.execute_reply.started":"2025-06-15T08:22:29.250376Z","shell.execute_reply":"2025-06-15T08:22:31.130065Z"}},"outputs":[{"name":"stdout","text":"After dtype optimisation mem: 1420.9 MB\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def split_max(x):\n    try:\n        return max(map(int, x.split(';')))\n    except:\n        return np.nan\n\ndf['seats_numeric'] = df['seats'].progress_apply(split_max)\ndf.drop('seats', axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:22:31.131868Z","iopub.execute_input":"2025-06-15T08:22:31.132087Z","iopub.status.idle":"2025-06-15T08:22:31.955106Z","shell.execute_reply.started":"2025-06-15T08:22:31.132070Z","shell.execute_reply":"2025-06-15T08:22:31.954533Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/604046 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fc8a1e99203421c914330557662a1a1"}},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"### Преобразование мульти­категорий в дамми-признаки  \nВ этой ячейке мы:  \n- Собираем все уникальные значения из колонок с «;»  \n- Создаём бинарные столбцы для каждого уникального тега/опции/оборудования  \n- Считаем, сколько элементов было в каждой строке","metadata":{}},{"cell_type":"code","source":"def get_uniques(series):\n    u = set()\n    for v in series.dropna():\n        for w in v.split(\";\"):\n            w = w.strip()\n            if w:\n                u.add(w)\n    return list(u)\n\n\nmulti_cols = [\"tags\", \"complectation_available_options\", \"equipment\"]\nuniques = {c: get_uniques(df[c]) for c in multi_cols}\n\n\ndef make_dummies(df, col, uniq):\n    out = (\n        df[col]\n        .str.get_dummies(sep=\";\")\n        .reindex(columns=uniq, fill_value=0)\n        .astype(\"int8\")\n    )\n    out.columns = [f\"{col}__{c}\" for c in uniq]\n    df[f\"{col}_cnt\"] = df[col].progress_apply(\n        lambda x: len(str(x).split(\";\")) if pd.notna(x) else 0\n    )\n    return out\n\n\ntags_d = make_dummies(df, \"tags\", uniques[\"tags\"])\nopts_d = make_dummies(\n    df,\n    \"complectation_available_options\",\n    uniques[\"complectation_available_options\"],\n).drop(columns=[\"complectation_available_options__condition\"], errors=\"ignore\")\neq_d = make_dummies(df, \"equipment\", uniques[\"equipment\"]).drop(\n    columns=[\"equipment__condition\"], errors=\"ignore\"\n)\n\nfull = pd.concat([df.drop(multi_cols, axis=1), tags_d, opts_d, eq_d], axis=1)\ndel tags_d, opts_d, eq_d\ngc.collect()\nprint(\"Dummies created, shape:\", full.shape, \"mem:\", mem_usage(full))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:22:31.955872Z","iopub.execute_input":"2025-06-15T08:22:31.956130Z","iopub.status.idle":"2025-06-15T08:25:44.494969Z","shell.execute_reply.started":"2025-06-15T08:22:31.956107Z","shell.execute_reply":"2025-06-15T08:25:44.494109Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/604046 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1274e6b7f8e543c1aeaff3f586f235c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/604046 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f92972193dc4bb88b0ed55b3dbefeda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/604046 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c5f77e0ebc0424e9398cabb94ec6588"}},"metadata":{}},{"name":"stdout","text":"Dummies created, shape: (604046, 590) mem: 753.8 MB\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### Отбраковка сильно коррелирующих признаков\nЗдесь мы:\n\n- Вычисляем корреляцию всех числовых признаков между собой\n\n- Удаляем одну из пары признаков с корреляцией > 0.8\n\n- Сохраняем важные столбцы (цену, год выпуска и счётчики мульти-категорий)","metadata":{}},{"cell_type":"code","source":"num = full.select_dtypes(include=[\"number\"]).drop(\n    columns=[\"price\"], errors=\"ignore\"\n)\n\ncorr = num.corr().abs()\nmask = np.triu(np.ones(corr.shape), 1).astype(bool)\nupper = corr.where(mask)\nmean_corr = corr.mean()\n\ndrop = set()\nfor i, j in zip(*np.where(upper > 0.80)):\n    a, b = corr.index[i], corr.columns[j]\n    drop.add(a if mean_corr[a] > mean_corr[b] else b)\n\n# защищаем важные признаки от удаления\nessential_cols = {\n    \"price\",\n    \"production_year\",  # уже были\n    \"tags_cnt\",\n    \"equipment_cnt\",\n    \"complectation_available_options_cnt\",  # NEW\n}\ndrop -= essential_cols\n\nf = full.drop(columns=drop, errors=\"ignore\").copy()\nprint(\"After corr-pruning shape:\", f.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:25:44.496484Z","iopub.execute_input":"2025-06-15T08:25:44.496712Z","iopub.status.idle":"2025-06-15T08:33:23.824581Z","shell.execute_reply.started":"2025-06-15T08:25:44.496694Z","shell.execute_reply":"2025-06-15T08:33:23.823952Z"}},"outputs":[{"name":"stdout","text":"After corr-pruning shape: (604046, 426)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### Создание новых признаков  \nВ этой ячейке мы:\n- Добавляем полиномиальные признаки (год²), логарифмические трансформации и отношения (пробег в год, мощность на литр и т.п.)\n- Рассчитываем возраст автомобиля и на его основе новые фичи: `age_x_power`, `power_per_year` и пр.\n- Вводим булевы индикаторы: один владелец, новый автомобиль, «очень старый»\n- Бинируем возраст и пробег в категории с помощью `pd.cut` и `pd.qcut`\n- Удаляем исходные столбцы `production_year` и `engine_displacement`","metadata":{}},{"cell_type":"code","source":"# НОВЫЕ ПРИЗНАКИ\nf[\"production_year_sq\"] = f[\"production_year\"] ** 2\nf[\"age\"] = 2025 - f[\"production_year\"]\nf[\"mileage_per_year\"] = f[\"mileage\"] / f[\"age\"].clip(1)\nf[\"log_mileage\"] = np.log1p(f[\"mileage\"])\nf[\"power_per_liter\"] = f[\"engine_power\"] / f[\"engine_displacement\"].clip(0.1)\nf[\"age_x_power\"] = f[\"age\"] * f[\"engine_power\"]\nf[\"age_x_mileage\"] = f[\"age\"] * f[\"mileage\"]\nf[\"log_disp\"] = np.log1p(f[\"engine_displacement\"])\nf[\"disp_per_door\"] = f[\"engine_displacement\"] / f[\"doors_count\"].clip(1)\nf[\"is_one_owner\"] = (f[\"owners_number\"] == 1).astype(int)\nf[\"is_new\"] = ((f[\"mileage\"] < 1000) & (f[\"owners_number\"] <= 1)).astype(int)\nf[\"is_very_old\"] = (f[\"age\"] > 20).astype(int)\nf[\"power_per_year\"] = f[\"engine_power\"] / (f[\"age\"] + 1)\nf[\"age_x_mileage\"] = f[\"age\"] * f[\"mileage\"]  # уже был – перезаписываем, ок\n\nf[\"age_bucket\"] = pd.cut(\n    f[\"age\"], bins=[-1, 0, 3, 7, 12, 20, 35, 100, np.inf], labels=False\n)\nf[\"mileage_bucket\"] = pd.qcut(\n    f[\"mileage\"], q=10, duplicates=\"drop\", labels=False\n)\n\n# Убираем теперь ненужные столбцы\nf.drop([\"production_year\", \"engine_displacement\"], axis=1, inplace=True)\nprint(\"Final feature DF shape:\", f.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:33:23.832664Z","iopub.execute_input":"2025-06-15T08:33:23.832865Z","iopub.status.idle":"2025-06-15T08:33:24.096284Z","shell.execute_reply.started":"2025-06-15T08:33:23.832850Z","shell.execute_reply":"2025-06-15T08:33:24.095494Z"}},"outputs":[{"name":"stdout","text":"Final feature DF shape: (604046, 439)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### Разбиение и подготовка данных  \n- Делим на train/test (15%) и сбрасываем индексы  \n- Применяем `log1p` к цене  \n- Строим сглаженную среднюю цену по бренду и мержим её в оба датасета","metadata":{}},{"cell_type":"code","source":"train_df, test_df = train_test_split(f, test_size=0.15, random_state=SEED)\ntrain_df = train_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)\n\ntrain_df[\"price_log\"] = np.log1p(train_df[\"price\"])\ntest_df[\"price_log\"] = np.log1p(test_df[\"price\"])\n\nglobal_mean = train_df[\"price\"].mean()\nα = 10  # коэффициент сглаживания\n\nsmoothing_stats = (\n    train_df.groupby(\"brand\")[\"price\"]\n    .agg([\"count\", \"mean\"])\n    .rename(columns={\"count\": \"brand_count\", \"mean\": \"brand_mean\"})\n)\n\nsmoothing_stats[\"brand_price_smooth\"] = (\n    smoothing_stats[\"brand_mean\"] * smoothing_stats[\"brand_count\"]\n    + global_mean * α\n) / (smoothing_stats[\"brand_count\"] + α)\n\n# мёржим сглаженные значения\ntrain_df = train_df.merge(\n    smoothing_stats[[\"brand_price_smooth\"]], on=\"brand\", how=\"left\"\n)\n\ntest_df = test_df.merge(\n    smoothing_stats[\"brand_price_smooth\"], on=\"brand\", how=\"left\"\n)\n\ntest_df[\"brand_price_smooth\"].fillna(global_mean, inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:33:24.099548Z","iopub.execute_input":"2025-06-15T08:33:24.099799Z","iopub.status.idle":"2025-06-15T08:33:25.247979Z","shell.execute_reply.started":"2025-06-15T08:33:24.099776Z","shell.execute_reply":"2025-06-15T08:33:25.247379Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### OOF Target- и Frequency-Encoding категорий  \n- Для каждого категориального признака из `cat_cols` выполняем KFold-оценку:  \n  - Строим out-of-fold target-encoding на основе средней цены.  \n  - Сохраняем карту средних для теста.  \n- Одновременно считаем frequency-encoding (долю каждого значения) и добавляем в train/test.","metadata":{}},{"cell_type":"code","source":"cat_cols = [\n    \"condition\",\n    \"accidents_resolution\",\n    \"region\",\n    \"seller_type\",\n    \"brand\",\n    \"model\",\n    \"body_type\",\n    \"steering_wheel\",\n    \"price_segment\",\n    \"auto_class\",\n]\n\nte_maps = {}\nfreq_cols = []\nkf = KFold(n_splits=5, shuffle=True, random_state=SEED)\nglobal_mean = train_df[\"price\"].mean()\n\nfor col in tqdm(cat_cols, desc=\"Target/Freq enc\"):\n    # OOF-target-encoding\n    oof = pd.Series(index=train_df.index, dtype=float)\n    for tr_idx, vl_idx in kf.split(train_df):\n        means = train_df.iloc[tr_idx].groupby(col)[\"price\"].mean()\n        oof.iloc[vl_idx] = (\n            train_df.iloc[vl_idx][col].map(means).fillna(global_mean)\n        )\n    train_df[col + \"_te\"] = oof\n    te_map = train_df.groupby(col)[\"price\"].mean()\n    te_maps[col] = te_map\n    test_df[col + \"_te\"] = test_df[col].map(te_map).fillna(global_mean)\n\n    # freq-encoding\n    freq = train_df[col].value_counts(normalize=True)\n    train_df[col + \"_fe\"] = train_df[col].map(freq)\n    test_df[col + \"_fe\"] = test_df[col].map(freq).fillna(0)\n    freq_cols.append(col + \"_fe\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:33:25.251255Z","iopub.execute_input":"2025-06-15T08:33:25.251477Z","iopub.status.idle":"2025-06-15T08:33:44.252112Z","shell.execute_reply.started":"2025-06-15T08:33:25.251456Z","shell.execute_reply":"2025-06-15T08:33:44.251257Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Target/Freq enc:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d16c880a9aa41d5b6d86b48575db951"}},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"### Масштабирование числовых признаков\n\nподготавливаем числовые признаки к обучению модели:\n\n- Собираем список всех числовых колонок: оригинальные (`num_cols`), таргет-энкодинги (`te_cols`) и частотные признаки (`freq_cols`).\n- Удаляем из списка отсутствующие колонки (на случай, если они были отброшены ранее)\n- Заполняем пропущенные значения нулями\n- Применяем `StandardScaler` для нормализации всех признаков.","metadata":{}},{"cell_type":"code","source":"num_cols = [\n    \"mileage\",\n    \"owners_number\",\n    \"doors_count\",\n    \"engine_power\",\n    \"fuel_rate\",\n    \"production_year_sq\",\n    \"age\",\n    \"mileage_per_year\",\n    \"log_mileage\",\n    \"power_per_liter\",\n    \"age_x_power\",\n    \"age_x_mileage\",\n    \"log_disp\",\n    \"disp_per_door\",\n    \"is_one_owner\",\n    \"is_new\",\n    \"is_very_old\",\n    \"power_per_year\",\n    \"seats_numeric\",\n    \"brand_price_smooth\",\n    \"age_bucket\",\n    \"mileage_bucket\",\n    \"tags_cnt\",\n    \"equipment_cnt\",\n    \"complectation_available_options_cnt\",\n]\n\nte_cols = [c + \"_te\" for c in cat_cols]\nall_num = num_cols + freq_cols + te_cols\n\n# убираем колонки, которых в DataFrame реально нет\nall_num = [c for c in all_num if c in train_df.columns]\n\n# заполняем возможные NaN, чтобы StandardScaler не упал\ntrain_df[all_num] = train_df[all_num].fillna(0)\ntest_df[all_num] = test_df[all_num].fillna(0)\n\nscaler = StandardScaler().fit(train_df[all_num])\njoblib.dump(scaler, \"scaler.pkl\")\n\ntrain_df[all_num] = scaler.transform(train_df[all_num])\ntest_df[all_num] = scaler.transform(test_df[all_num])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:33:44.625782Z","iopub.execute_input":"2025-06-15T08:33:44.626161Z","iopub.status.idle":"2025-06-15T08:33:45.677501Z","shell.execute_reply.started":"2025-06-15T08:33:44.626143Z","shell.execute_reply":"2025-06-15T08:33:45.676734Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"### Подготовка Dataset и DataLoader","metadata":{}},{"cell_type":"code","source":"class CarDataset(Dataset):\n    def __init__(self, df, use_log=False):\n        target = \"price_log\" if use_log else \"price\"\n        self.y = torch.tensor(df[target].values, dtype=torch.float32)\n        self.num = torch.tensor(df[all_num].values, dtype=torch.float32)\n        self.cat = torch.tensor(df[label_code_cols].values, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return self.num[idx], self.cat[idx], self.y[idx]\n\n\nbatch = 256\ntrain_loader = DataLoader(\n    CarDataset(train_df), batch_size=batch, shuffle=True, num_workers=0\n)\nval_loader = DataLoader(\n    CarDataset(test_df), batch_size=batch, shuffle=False, num_workers=0\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:33:45.678364Z","iopub.execute_input":"2025-06-15T08:33:45.678576Z","iopub.status.idle":"2025-06-15T08:33:46.098307Z","shell.execute_reply.started":"2025-06-15T08:33:45.678559Z","shell.execute_reply":"2025-06-15T08:33:46.097648Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## 5. Модель и обучение","metadata":{}},{"cell_type":"markdown","source":"### Обзор архитектуры\n\nВ этой ячейке реализована модель по аналогии TabNet для задачи регрессии на табличных данных. Основные компоненты:\n\n1. **FeatureBlock**  \n   - Линейное преобразование входа → `output_dim` (или `2×` при включённом GLU)  \n   - LayerNorm + Dropout  \n   - Опциональный GLU‑гейт: делит выход на две части и умножает «фичи» на сигмоиду «ворот»\n\n2. **Sparsemax**  \n   - Жёсткий аналог softmax  \n   - Выдаёт разреженные веса суммы 1, обнуляя маловажные элементы\n\n3. **AttentiveTransformer**  \n   - Преобразует скрытое представление `x_trans` (размер `feature_dim`) в «маску внимания» по исходным признакам (`input_dim`)  \n   - Учитывает «prior» (остаточную важность), чтобы последующие шаги смотрели на новые признаки\n\n4. **FeatureTransformer**  \n   - Состоит из:\n     1. **Первого блока**: `input_dim → feature_dim`  \n     2. **Shared‑блоков** (GLU + residual) внутри `feature_dim`  \n     3. **Step‑блоков** (GLU + residual) внутри `feature_dim`\n   - Дает гибкое нелинейное представление отобранных признаков\n\n5. **TabNetRegressor**  \n   - Первичная трансформация всего `x` через `FeatureTransformer`  \n   - Цикл из `n_steps`:\n     1. `AttentiveTransformer` → маска внимания  \n     2. Обновление `prior = prior * (relaxation - mask)`  \n     3. Поэлементное умножение `x_masked = mask * x`  \n     4. Обработка `x_masked` через `FeatureTransformer` → `x_step`  \n     5. Суммирование в аккумулятор `total_o += x_step`  \n   - В конце простой линейный регрессор `nn.Linear(feature_dim, output_dim)`","metadata":{}},{"cell_type":"code","source":"import math\nimport torch\nimport torch.nn as nn\nfrom torch.optim.lr_scheduler import OneCycleLR\n\n\nclass FeatureBlock(nn.Module):\n    def __init__(self, input_dim, output_dim, apply_glu=True, dropout=0.2):\n        super().__init__()\n        self.apply_glu = apply_glu\n        fc_out = output_dim * (2 if apply_glu else 1)\n        self.fc = nn.Linear(input_dim, fc_out, bias=False)\n        self.norm = nn.LayerNorm(fc_out, eps=1e-6)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        x = self.fc(x)\n        x = self.norm(x)\n        if self.apply_glu:\n            out, gate = x.chunk(2, dim=1)\n            x = out * torch.sigmoid(gate)\n        return self.dropout(x)\n\n\n# Sparsemax для attention\nclass Sparsemax(nn.Module):\n    def __init__(self, dim=1):\n        super().__init__()\n        self.dim = dim\n\n    def forward(self, inp):\n        sorted_, _ = torch.sort(inp, descending=True, dim=self.dim)\n        cumsum_ = torch.cumsum(sorted_, dim=self.dim)\n        k_range = torch.arange(\n            1, inp.size(self.dim) + 1, device=inp.device, dtype=inp.dtype\n        )\n        k_range = k_range.view([1] * (inp.dim() - 1) + [-1])\n        support = sorted_ - (cumsum_ - 1) / k_range > 0\n        k = support.sum(dim=self.dim, keepdim=True)\n        tau_sum = torch.gather(cumsum_, self.dim, k - 1).squeeze(self.dim)\n        tau = (tau_sum - 1) / k.squeeze(self.dim)\n        return torch.clamp(inp - tau.unsqueeze(self.dim), min=0)\n\n\nclass AttentiveTransformer(nn.Module):\n    def __init__(self, feature_dim, input_dim, dropout=0.2):\n        super().__init__()\n        self.block = FeatureBlock(\n            feature_dim, input_dim, apply_glu=False, dropout=dropout\n        )\n        self.sparsemax = Sparsemax(dim=1)\n\n    def forward(self, x_transformed, prior):\n        x = self.block(x_transformed)\n        x = x * prior\n        return self.sparsemax(x)\n\n\nclass FeatureTransformer(nn.Module):\n    def __init__(self, input_dim, feature_dim, n_shared=3, n_total=6, dropout=0.2):\n        super().__init__()\n        self.first = FeatureBlock(input_dim, feature_dim, apply_glu=True, dropout=dropout)\n        self.shared_blocks = nn.ModuleList(\n            [\n                FeatureBlock(feature_dim, feature_dim, apply_glu=True, dropout=dropout)\n                for _ in range(n_shared - 1)\n            ]\n        )\n        self.step_blocks = nn.ModuleList(\n            [\n                FeatureBlock(feature_dim, feature_dim, apply_glu=True, dropout=dropout)\n                for _ in range(n_total - n_shared)\n            ]\n        )\n\n    def forward(self, x):\n        # первый блок без residual\n        out = self.first(x)\n        # с residual\n        for blk in self.shared_blocks:\n            y = blk(out)\n            out = y + out * math.sqrt(0.5)\n        # с residual\n        for blk in self.step_blocks:\n            y = blk(out)\n            out = y + out * math.sqrt(0.5)\n        return out\n\n\nclass TabNetRegressor(nn.Module):\n    def __init__(\n        self,\n        input_dim,\n        feature_dim=128,\n        output_dim=1,\n        n_steps=4,\n        n_shared=3,\n        relaxation=1.3,\n        dropout=0.2,\n    ):\n        super().__init__()\n        self.feature_dim = feature_dim\n        self.n_steps = n_steps\n        self.relaxation = relaxation\n\n        self.initial_transform = FeatureTransformer(\n            input_dim=input_dim,\n            feature_dim=feature_dim,\n            n_shared=n_shared,\n            n_total=2 * n_shared,\n            dropout=dropout,\n        )\n\n        self.attentive_transformers = nn.ModuleList()\n        self.feature_transformers = nn.ModuleList()\n        for _ in range(n_steps):\n            self.attentive_transformers.append(\n                AttentiveTransformer(feature_dim, input_dim, dropout=dropout)\n            )\n            self.feature_transformers.append(\n                FeatureTransformer(\n                    input_dim=input_dim,\n                    feature_dim=feature_dim,\n                    n_shared=n_shared,\n                    n_total=4,\n                    dropout=dropout,\n                )\n            )\n\n        self.regressor = nn.Linear(feature_dim, output_dim)\n\n    def forward(self, x):\n        B, D = x.size()\n        # Первичное преобразование\n        x_trans = self.initial_transform(x)  # (B, feature_dim)\n        total_o = torch.zeros(B, self.feature_dim, device=x.device)\n        prior = torch.ones(B, D, device=x.device)\n\n        for i in range(self.n_steps):\n            mask = self.attentive_transformers[i](x_trans, prior)\n            prior = prior * (self.relaxation - mask)\n            x_masked = mask * x\n            x_step = self.feature_transformers[i](x_masked)\n            total_o += x_step\n\n        return self.regressor(total_o).squeeze(1)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:33:46.099141Z","iopub.execute_input":"2025-06-15T08:33:46.099668Z","iopub.status.idle":"2025-06-15T08:33:46.118042Z","shell.execute_reply.started":"2025-06-15T08:33:46.099644Z","shell.execute_reply":"2025-06-15T08:33:46.117448Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"### Настройка обучения  \n\n","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = TabNetRegressor(input_dim=len(all_num)).to(device)\nopt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\nEPOCHS = 300\nsteps_per_epoch = len(train_loader)\n\nsched = OneCycleLR(\n    optimizer=opt,\n    max_lr=1e-2,\n    steps_per_epoch=steps_per_epoch,\n    epochs=EPOCHS,\n    pct_start=0.3,\n    div_factor=10,\n    final_div_factor=1000,\n)\n\ncriterion = nn.SmoothL1Loss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:33:46.118623Z","iopub.execute_input":"2025-06-15T08:33:46.118832Z","iopub.status.idle":"2025-06-15T08:33:48.835896Z","shell.execute_reply.started":"2025-06-15T08:33:46.118817Z","shell.execute_reply":"2025-06-15T08:33:48.835335Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"### Цикл обучения и валидации","metadata":{}},{"cell_type":"code","source":"# Training loop\nfor epoch in trange(1, EPOCHS + 1, desc=\"Epochs\"):\n    # ===== TRAIN =====\n    model.train()\n    train_losses = []\n    for xn, _, y_price in train_loader:\n        xn = xn.to(device)\n        y_price = y_price.to(device)\n\n        opt.zero_grad()\n        preds = model(xn)\n        loss = criterion(preds, y_price)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        opt.step()\n        sched.step()  # step per batch\n\n        train_losses.append(loss.item())\n\n    mean_train_loss = sum(train_losses) / len(train_losses)\n\n    # ===== VALIDATION =====\n    model.eval()\n    val_losses, all_preds, all_trues = [], [], []\n    with torch.no_grad():\n        for xn, _, y_price in val_loader:\n            xn = xn.to(device)\n            y_price = y_price.to(device)\n\n            preds = model(xn)\n            loss = criterion(preds, y_price)\n\n            val_losses.append(loss.item())\n            all_preds.append(preds.cpu())\n            all_trues.append(y_price.cpu())\n\n    mean_val_loss = sum(val_losses) / len(val_losses)\n    preds = torch.cat(all_preds).numpy()\n    trues = torch.cat(all_trues).numpy()\n\n    rmse = mean_squared_error(trues, preds, squared=False)\n    r2 = r2_score(trues, preds)\n\n    # ===== PRINT =====\n    if epoch % 5 == 0:\n        print(\n            f\"Epoch {epoch:3d} | Train Loss: {mean_train_loss:.4f} | \"\n            f\"Val Loss: {mean_val_loss:.4f} | RMSE: {rmse:.2f} | R2: {r2:.4f}\"\n        )\n    else:\n        print(\n            f\"Epoch {epoch:3d} | Train Loss: {mean_train_loss:.4f} | \"\n            f\"Val Loss: {mean_val_loss:.4f} | RMSE: {rmse:.2f}\"\n        )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:33:48.837977Z","iopub.execute_input":"2025-06-15T08:33:48.838476Z","iopub.status.idle":"2025-06-15T11:50:13.605991Z","shell.execute_reply.started":"2025-06-15T08:33:48.838458Z","shell.execute_reply":"2025-06-15T11:50:13.605243Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Epochs:   0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c828e0acf7f4609b4ae2d0bed54776f"}},"metadata":{}},{"name":"stdout","text":"Epoch   1 | Train Loss: 2801163.1415 | Val Loss: 2787061.4696 | RMSE: 6144008.00\nEpoch   2 | Train Loss: 2768886.6004 | Val Loss: 2740000.5028 | RMSE: 6122782.50\nEpoch   3 | Train Loss: 2708672.4371 | Val Loss: 2667585.7444 | RMSE: 6090023.00\nEpoch   4 | Train Loss: 2625183.8004 | Val Loss: 2573787.0579 | RMSE: 6046049.00\nEpoch   5 | Train Loss: 2526684.1674 | Val Loss: 2481351.6412 | RMSE: 6002736.00 | R2: -0.2019\nEpoch   6 | Train Loss: 2448096.8063 | Val Loss: 2410079.0547 | RMSE: 5969051.00\nEpoch   7 | Train Loss: 2374717.6262 | Val Loss: 2327036.2037 | RMSE: 5929117.00\nEpoch   8 | Train Loss: 2276728.5990 | Val Loss: 2213476.1585 | RMSE: 5872746.50\nEpoch   9 | Train Loss: 2152229.3630 | Val Loss: 2079783.4428 | RMSE: 5805147.50\nEpoch  10 | Train Loss: 2012676.0252 | Val Loss: 1931696.7157 | RMSE: 5728167.00 | R2: -0.0944\nEpoch  11 | Train Loss: 1858437.2074 | Val Loss: 1774706.5318 | RMSE: 5645115.00\nEpoch  12 | Train Loss: 1697453.0607 | Val Loss: 1607108.2052 | RMSE: 5555355.00\nEpoch  13 | Train Loss: 1531469.8197 | Val Loss: 1443726.3459 | RMSE: 5463739.50\nEpoch  14 | Train Loss: 1377300.1798 | Val Loss: 1293794.0946 | RMSE: 5375286.50\nEpoch  15 | Train Loss: 1238086.1908 | Val Loss: 1163006.2272 | RMSE: 5288103.50 | R2: 0.0673\nEpoch  16 | Train Loss: 1121155.8037 | Val Loss: 1051960.3683 | RMSE: 5206421.50\nEpoch  17 | Train Loss: 1025346.9096 | Val Loss: 963693.5435 | RMSE: 5127649.00\nEpoch  18 | Train Loss: 946339.9176 | Val Loss: 886156.9236 | RMSE: 5050403.50\nEpoch  19 | Train Loss: 878757.0762 | Val Loss: 818776.3621 | RMSE: 4973892.50\nEpoch  20 | Train Loss: 823240.9286 | Val Loss: 771194.6112 | RMSE: 4901548.00 | R2: 0.1986\nEpoch  21 | Train Loss: 779296.4449 | Val Loss: 722162.7010 | RMSE: 4833609.00\nEpoch  22 | Train Loss: 729189.7989 | Val Loss: 675421.7182 | RMSE: 4761360.00\nEpoch  23 | Train Loss: 692321.2767 | Val Loss: 644965.0819 | RMSE: 4703134.00\nEpoch  24 | Train Loss: 662169.5451 | Val Loss: 618589.0576 | RMSE: 4649261.00\nEpoch  25 | Train Loss: 635844.5796 | Val Loss: 590625.4669 | RMSE: 4586011.00 | R2: 0.2985\nEpoch  26 | Train Loss: 612771.4867 | Val Loss: 564061.8678 | RMSE: 4535741.00\nEpoch  27 | Train Loss: 591006.6584 | Val Loss: 567547.5614 | RMSE: 4489997.00\nEpoch  28 | Train Loss: 570748.0699 | Val Loss: 524233.2545 | RMSE: 4436048.50\nEpoch  29 | Train Loss: 552393.3104 | Val Loss: 512921.7050 | RMSE: 4391049.50\nEpoch  30 | Train Loss: 537668.2525 | Val Loss: 486817.1366 | RMSE: 4357368.00 | R2: 0.3667\nEpoch  31 | Train Loss: 519915.0617 | Val Loss: 477857.2245 | RMSE: 4306619.00\nEpoch  32 | Train Loss: 504566.5305 | Val Loss: 456281.1898 | RMSE: 4276692.00\nEpoch  33 | Train Loss: 490801.8513 | Val Loss: 451250.1415 | RMSE: 4243334.50\nEpoch  34 | Train Loss: 480924.6456 | Val Loss: 437052.8832 | RMSE: 4220513.00\nEpoch  35 | Train Loss: 470674.8805 | Val Loss: 431081.9141 | RMSE: 4205839.50 | R2: 0.4100\nEpoch  36 | Train Loss: 463028.1573 | Val Loss: 427537.2441 | RMSE: 4163691.75\nEpoch  37 | Train Loss: 457131.6399 | Val Loss: 420148.7396 | RMSE: 4158355.75\nEpoch  38 | Train Loss: 452123.1577 | Val Loss: 418725.8763 | RMSE: 4136884.50\nEpoch  39 | Train Loss: 447648.6668 | Val Loss: 405220.7251 | RMSE: 4127016.00\nEpoch  40 | Train Loss: 443632.4814 | Val Loss: 408763.1347 | RMSE: 4117086.25 | R2: 0.4346\nEpoch  41 | Train Loss: 439911.6259 | Val Loss: 402879.6759 | RMSE: 4096961.50\nEpoch  42 | Train Loss: 436431.5096 | Val Loss: 395595.9316 | RMSE: 4080921.75\nEpoch  43 | Train Loss: 433692.1732 | Val Loss: 397568.6195 | RMSE: 4079279.00\nEpoch  44 | Train Loss: 431060.8523 | Val Loss: 389308.4680 | RMSE: 4063474.00\nEpoch  45 | Train Loss: 428517.3941 | Val Loss: 381775.4267 | RMSE: 4044289.25 | R2: 0.4544\nEpoch  46 | Train Loss: 423456.3830 | Val Loss: 383048.1619 | RMSE: 4034758.25\nEpoch  47 | Train Loss: 420914.0706 | Val Loss: 381286.4624 | RMSE: 4021697.50\nEpoch  48 | Train Loss: 416390.3487 | Val Loss: 377380.6873 | RMSE: 4029325.75\nEpoch  49 | Train Loss: 411865.3583 | Val Loss: 376008.5831 | RMSE: 3999672.75\nEpoch  50 | Train Loss: 411903.4718 | Val Loss: 376024.3226 | RMSE: 3989734.75 | R2: 0.4691\nEpoch  51 | Train Loss: 408777.1514 | Val Loss: 367218.7576 | RMSE: 3998016.00\nEpoch  52 | Train Loss: 404907.4064 | Val Loss: 363726.4507 | RMSE: 3981774.50\nEpoch  53 | Train Loss: 402601.5923 | Val Loss: 365849.3581 | RMSE: 4015381.75\nEpoch  54 | Train Loss: 400023.7384 | Val Loss: 360532.8241 | RMSE: 3993206.75\nEpoch  55 | Train Loss: 398448.4867 | Val Loss: 359451.7271 | RMSE: 3960059.50 | R2: 0.4769\nEpoch  56 | Train Loss: 396920.5998 | Val Loss: 364507.6093 | RMSE: 3942965.50\nEpoch  57 | Train Loss: 395039.2224 | Val Loss: 364033.1679 | RMSE: 3946434.50\nEpoch  58 | Train Loss: 393940.1693 | Val Loss: 358096.8113 | RMSE: 3932776.75\nEpoch  59 | Train Loss: 393791.6001 | Val Loss: 356937.5077 | RMSE: 3946501.00\nEpoch  60 | Train Loss: 392781.7952 | Val Loss: 359072.3169 | RMSE: 3966813.75 | R2: 0.4751\nEpoch  61 | Train Loss: 391983.7251 | Val Loss: 365585.2222 | RMSE: 3915654.25\nEpoch  62 | Train Loss: 389912.3581 | Val Loss: 357251.4375 | RMSE: 3916190.25\nEpoch  63 | Train Loss: 388524.1042 | Val Loss: 354403.2899 | RMSE: 3909447.75\nEpoch  64 | Train Loss: 386531.7817 | Val Loss: 348284.8285 | RMSE: 3909755.00\nEpoch  65 | Train Loss: 385335.7642 | Val Loss: 353764.0855 | RMSE: 3928548.25 | R2: 0.4852\nEpoch  66 | Train Loss: 384502.8699 | Val Loss: 349279.8118 | RMSE: 3905946.00\nEpoch  67 | Train Loss: 383248.6651 | Val Loss: 355860.2391 | RMSE: 3957300.75\nEpoch  68 | Train Loss: 381222.9709 | Val Loss: 354477.7352 | RMSE: 3907065.75\nEpoch  69 | Train Loss: 380163.7862 | Val Loss: 345870.0618 | RMSE: 3921671.25\nEpoch  70 | Train Loss: 380186.8059 | Val Loss: 346553.0441 | RMSE: 3915916.25 | R2: 0.4885\nEpoch  71 | Train Loss: 376874.2897 | Val Loss: 336562.1287 | RMSE: 3898935.25\nEpoch  72 | Train Loss: 376455.0875 | Val Loss: 341053.7825 | RMSE: 3870682.25\nEpoch  73 | Train Loss: 377150.9199 | Val Loss: 352003.6595 | RMSE: 3904788.25\nEpoch  74 | Train Loss: 375165.3322 | Val Loss: 335804.9691 | RMSE: 3908241.00\nEpoch  75 | Train Loss: 376034.1861 | Val Loss: 336250.8623 | RMSE: 3879422.50 | R2: 0.4980\nEpoch  76 | Train Loss: 373655.3431 | Val Loss: 339860.5465 | RMSE: 3886016.50\nEpoch  77 | Train Loss: 373039.6689 | Val Loss: 334971.1820 | RMSE: 3850356.25\nEpoch  78 | Train Loss: 371816.4822 | Val Loss: 333313.9188 | RMSE: 3846132.25\nEpoch  79 | Train Loss: 368497.6912 | Val Loss: 343162.9675 | RMSE: 3944118.50\nEpoch  80 | Train Loss: 368598.4856 | Val Loss: 334032.6657 | RMSE: 3865158.00 | R2: 0.5017\nEpoch  81 | Train Loss: 369728.2589 | Val Loss: 331372.5128 | RMSE: 3864821.00\nEpoch  82 | Train Loss: 367952.5767 | Val Loss: 331203.1292 | RMSE: 3846763.75\nEpoch  83 | Train Loss: 366354.0299 | Val Loss: 327251.7406 | RMSE: 3846151.25\nEpoch  84 | Train Loss: 365002.3664 | Val Loss: 342334.7028 | RMSE: 3831046.00\nEpoch  85 | Train Loss: 365368.5545 | Val Loss: 331994.9577 | RMSE: 3832195.00 | R2: 0.5102\nEpoch  86 | Train Loss: 364536.5109 | Val Loss: 323416.0590 | RMSE: 3855865.75\nEpoch  87 | Train Loss: 362942.8861 | Val Loss: 325607.9578 | RMSE: 3821334.25\nEpoch  88 | Train Loss: 363448.7423 | Val Loss: 325798.9734 | RMSE: 3839506.75\nEpoch  89 | Train Loss: 361636.0530 | Val Loss: 325786.2664 | RMSE: 3819170.25\nEpoch  90 | Train Loss: 359863.4811 | Val Loss: 323567.1781 | RMSE: 3849694.50 | R2: 0.5057\nEpoch  91 | Train Loss: 361421.2940 | Val Loss: 329512.2590 | RMSE: 3829590.00\nEpoch  92 | Train Loss: 359786.5843 | Val Loss: 331566.1613 | RMSE: 3851226.75\nEpoch  93 | Train Loss: 359110.2688 | Val Loss: 327022.0424 | RMSE: 3838596.00\nEpoch  94 | Train Loss: 357651.2610 | Val Loss: 321176.2640 | RMSE: 3844742.00\nEpoch  95 | Train Loss: 357608.4518 | Val Loss: 320452.3950 | RMSE: 3845211.00 | R2: 0.5068\nEpoch  96 | Train Loss: 354777.6881 | Val Loss: 317330.0192 | RMSE: 3836389.00\nEpoch  97 | Train Loss: 355468.9278 | Val Loss: 320171.3803 | RMSE: 3814649.75\nEpoch  98 | Train Loss: 355990.5961 | Val Loss: 322471.7036 | RMSE: 3852381.00\nEpoch  99 | Train Loss: 355356.0399 | Val Loss: 319116.6659 | RMSE: 3835302.00\nEpoch 100 | Train Loss: 353791.7122 | Val Loss: 321824.2962 | RMSE: 3845928.50 | R2: 0.5066\nEpoch 101 | Train Loss: 352570.3007 | Val Loss: 315233.8256 | RMSE: 3826628.25\nEpoch 102 | Train Loss: 354080.3630 | Val Loss: 318297.6498 | RMSE: 3838921.75\nEpoch 103 | Train Loss: 354095.1659 | Val Loss: 321149.4061 | RMSE: 3840847.25\nEpoch 104 | Train Loss: 353167.8334 | Val Loss: 321979.9661 | RMSE: 3881197.00\nEpoch 105 | Train Loss: 350352.5015 | Val Loss: 311658.1076 | RMSE: 3872955.25 | R2: 0.4997\nEpoch 106 | Train Loss: 350748.0879 | Val Loss: 311975.6092 | RMSE: 3856911.75\nEpoch 107 | Train Loss: 352301.8312 | Val Loss: 312505.8525 | RMSE: 3852391.50\nEpoch 108 | Train Loss: 350304.9837 | Val Loss: 316528.7414 | RMSE: 3832757.25\nEpoch 109 | Train Loss: 350415.7906 | Val Loss: 320266.2142 | RMSE: 3859926.75\nEpoch 110 | Train Loss: 347941.3421 | Val Loss: 323631.9505 | RMSE: 3820446.50 | R2: 0.5132\nEpoch 111 | Train Loss: 347979.2730 | Val Loss: 324987.7777 | RMSE: 3853297.75\nEpoch 112 | Train Loss: 346448.0831 | Val Loss: 310301.3137 | RMSE: 3852123.00\nEpoch 113 | Train Loss: 346562.9324 | Val Loss: 313183.5262 | RMSE: 3829860.50\nEpoch 114 | Train Loss: 345911.6457 | Val Loss: 312002.9324 | RMSE: 3800090.75\nEpoch 115 | Train Loss: 344472.1962 | Val Loss: 310071.5685 | RMSE: 3843875.75 | R2: 0.5072\nEpoch 116 | Train Loss: 345285.9893 | Val Loss: 312903.2934 | RMSE: 3825385.75\nEpoch 117 | Train Loss: 343190.4574 | Val Loss: 311215.0127 | RMSE: 3822491.00\nEpoch 118 | Train Loss: 344410.1681 | Val Loss: 309669.7830 | RMSE: 3816127.75\nEpoch 119 | Train Loss: 343973.7160 | Val Loss: 320603.1944 | RMSE: 3828034.25\nEpoch 120 | Train Loss: 341304.1385 | Val Loss: 310007.1198 | RMSE: 3802729.50 | R2: 0.5177\nEpoch 121 | Train Loss: 341885.0995 | Val Loss: 313529.4193 | RMSE: 3815014.50\nEpoch 122 | Train Loss: 341578.0578 | Val Loss: 310291.0711 | RMSE: 3824609.25\nEpoch 123 | Train Loss: 340763.9611 | Val Loss: 309631.5249 | RMSE: 3807334.50\nEpoch 124 | Train Loss: 339732.5207 | Val Loss: 310806.1233 | RMSE: 3788870.25\nEpoch 125 | Train Loss: 340374.0601 | Val Loss: 317087.8669 | RMSE: 3780844.75 | R2: 0.5232\nEpoch 126 | Train Loss: 338939.1268 | Val Loss: 307048.6180 | RMSE: 3792597.75\nEpoch 127 | Train Loss: 338617.0749 | Val Loss: 309243.2733 | RMSE: 3809984.00\nEpoch 128 | Train Loss: 338518.4333 | Val Loss: 305107.6489 | RMSE: 3821434.00\nEpoch 129 | Train Loss: 336518.9019 | Val Loss: 312952.8324 | RMSE: 3805695.00\nEpoch 130 | Train Loss: 337923.7167 | Val Loss: 308840.2042 | RMSE: 3807006.25 | R2: 0.5166\nEpoch 131 | Train Loss: 335949.8082 | Val Loss: 311760.5980 | RMSE: 3795934.00\nEpoch 132 | Train Loss: 338241.7068 | Val Loss: 313632.9651 | RMSE: 3803055.00\nEpoch 133 | Train Loss: 336121.7495 | Val Loss: 305817.7242 | RMSE: 3820944.25\nEpoch 134 | Train Loss: 335785.1716 | Val Loss: 309076.8928 | RMSE: 3784667.50\nEpoch 135 | Train Loss: 334303.0239 | Val Loss: 306006.8992 | RMSE: 3807957.50 | R2: 0.5163\nEpoch 136 | Train Loss: 335193.8443 | Val Loss: 310891.9696 | RMSE: 3816459.75\nEpoch 137 | Train Loss: 334308.0206 | Val Loss: 305314.3804 | RMSE: 3810184.75\nEpoch 138 | Train Loss: 333228.8974 | Val Loss: 305822.9176 | RMSE: 3791488.50\nEpoch 139 | Train Loss: 331515.8700 | Val Loss: 301739.2191 | RMSE: 3805129.25\nEpoch 140 | Train Loss: 331897.4282 | Val Loss: 305539.5524 | RMSE: 3821389.25 | R2: 0.5129\nEpoch 141 | Train Loss: 331773.1670 | Val Loss: 302568.1806 | RMSE: 3806010.25\nEpoch 142 | Train Loss: 330378.7094 | Val Loss: 309648.5617 | RMSE: 3798888.25\nEpoch 143 | Train Loss: 329110.3207 | Val Loss: 302120.4080 | RMSE: 3808289.00\nEpoch 144 | Train Loss: 329938.8638 | Val Loss: 302196.4026 | RMSE: 3779365.00\nEpoch 145 | Train Loss: 329557.7093 | Val Loss: 303814.9488 | RMSE: 3789690.25 | R2: 0.5210\nEpoch 146 | Train Loss: 328065.1225 | Val Loss: 308361.7826 | RMSE: 3794216.25\nEpoch 147 | Train Loss: 328337.6424 | Val Loss: 302431.9366 | RMSE: 3760419.50\nEpoch 148 | Train Loss: 329058.2702 | Val Loss: 296940.3568 | RMSE: 3777116.50\nEpoch 149 | Train Loss: 327123.3125 | Val Loss: 305820.7092 | RMSE: 3778327.00\nEpoch 150 | Train Loss: 327205.9531 | Val Loss: 312088.7853 | RMSE: 3782819.25 | R2: 0.5227\nEpoch 151 | Train Loss: 328058.4557 | Val Loss: 302509.9972 | RMSE: 3810574.25\nEpoch 152 | Train Loss: 326889.9653 | Val Loss: 307109.8470 | RMSE: 3782330.25\nEpoch 153 | Train Loss: 325699.8032 | Val Loss: 308564.1374 | RMSE: 3799376.75\nEpoch 154 | Train Loss: 325706.6745 | Val Loss: 304308.5627 | RMSE: 3786878.75\nEpoch 155 | Train Loss: 325480.5003 | Val Loss: 309521.2331 | RMSE: 3755870.75 | R2: 0.5295\nEpoch 156 | Train Loss: 325575.7467 | Val Loss: 305690.1976 | RMSE: 3760859.00\nEpoch 157 | Train Loss: 325141.7869 | Val Loss: 302548.9443 | RMSE: 3766579.25\nEpoch 158 | Train Loss: 324276.4635 | Val Loss: 296930.0930 | RMSE: 3788143.25\nEpoch 159 | Train Loss: 323458.1285 | Val Loss: 302640.8990 | RMSE: 3761685.50\nEpoch 160 | Train Loss: 324947.6232 | Val Loss: 295959.7905 | RMSE: 3752302.50 | R2: 0.5304\nEpoch 161 | Train Loss: 324934.2234 | Val Loss: 297225.6700 | RMSE: 3800126.25\nEpoch 162 | Train Loss: 322695.9059 | Val Loss: 299348.4523 | RMSE: 3775601.00\nEpoch 163 | Train Loss: 322549.4814 | Val Loss: 300231.1423 | RMSE: 3759386.50\nEpoch 164 | Train Loss: 323102.8953 | Val Loss: 307116.4030 | RMSE: 3767384.50\nEpoch 165 | Train Loss: 321620.7574 | Val Loss: 296179.3037 | RMSE: 3773352.50 | R2: 0.5251\nEpoch 166 | Train Loss: 322553.7414 | Val Loss: 304028.1248 | RMSE: 3808995.25\nEpoch 167 | Train Loss: 321972.8149 | Val Loss: 302420.2965 | RMSE: 3771657.75\nEpoch 168 | Train Loss: 322734.5349 | Val Loss: 298689.2353 | RMSE: 3772811.00\nEpoch 169 | Train Loss: 321106.3927 | Val Loss: 296602.9791 | RMSE: 3757776.75\nEpoch 170 | Train Loss: 320736.4065 | Val Loss: 296023.9567 | RMSE: 3790879.00 | R2: 0.5207\nEpoch 171 | Train Loss: 318902.3194 | Val Loss: 299129.8927 | RMSE: 3801190.25\nEpoch 172 | Train Loss: 320534.7034 | Val Loss: 301494.1065 | RMSE: 3774675.50\nEpoch 173 | Train Loss: 319739.7137 | Val Loss: 299458.8290 | RMSE: 3759680.25\nEpoch 174 | Train Loss: 317871.0896 | Val Loss: 303256.6089 | RMSE: 3753047.00\nEpoch 175 | Train Loss: 317073.2770 | Val Loss: 300815.3220 | RMSE: 3730238.25 | R2: 0.5359\nEpoch 176 | Train Loss: 316606.2111 | Val Loss: 292787.2294 | RMSE: 3737641.25\nEpoch 177 | Train Loss: 316028.8499 | Val Loss: 295202.8082 | RMSE: 3723826.25\nEpoch 178 | Train Loss: 315419.0741 | Val Loss: 303307.3264 | RMSE: 3748614.50\nEpoch 179 | Train Loss: 313797.2952 | Val Loss: 297473.6981 | RMSE: 3753523.25\nEpoch 180 | Train Loss: 315281.2386 | Val Loss: 298951.1841 | RMSE: 3749733.25 | R2: 0.5310\nEpoch 181 | Train Loss: 314639.7057 | Val Loss: 299892.0614 | RMSE: 3761129.25\nEpoch 182 | Train Loss: 313507.2386 | Val Loss: 300685.4197 | RMSE: 3731771.00\nEpoch 183 | Train Loss: 312652.3946 | Val Loss: 299268.7714 | RMSE: 3749157.50\nEpoch 184 | Train Loss: 313502.8840 | Val Loss: 298899.3403 | RMSE: 3736183.00\nEpoch 185 | Train Loss: 312265.1585 | Val Loss: 304213.2207 | RMSE: 3716561.25 | R2: 0.5393\nEpoch 186 | Train Loss: 312682.7120 | Val Loss: 304246.8279 | RMSE: 3688338.00\nEpoch 187 | Train Loss: 313004.2410 | Val Loss: 294027.1277 | RMSE: 3702137.25\nEpoch 188 | Train Loss: 310940.5559 | Val Loss: 301463.9665 | RMSE: 3731721.75\nEpoch 189 | Train Loss: 312179.2274 | Val Loss: 304047.0477 | RMSE: 3722268.50\nEpoch 190 | Train Loss: 311483.0115 | Val Loss: 299389.2036 | RMSE: 3737244.75 | R2: 0.5341\nEpoch 191 | Train Loss: 310527.2154 | Val Loss: 300816.4365 | RMSE: 3726927.00\nEpoch 192 | Train Loss: 310465.3204 | Val Loss: 299621.6779 | RMSE: 3748879.75\nEpoch 193 | Train Loss: 310103.3335 | Val Loss: 308107.6956 | RMSE: 3726131.25\nEpoch 194 | Train Loss: 310279.4856 | Val Loss: 303383.2142 | RMSE: 3731555.50\nEpoch 195 | Train Loss: 309640.3631 | Val Loss: 300817.2382 | RMSE: 3710955.25 | R2: 0.5407\nEpoch 196 | Train Loss: 309268.1015 | Val Loss: 306566.2873 | RMSE: 3710209.75\nEpoch 197 | Train Loss: 308601.2944 | Val Loss: 305678.3793 | RMSE: 3708796.50\nEpoch 198 | Train Loss: 307901.8065 | Val Loss: 312148.1812 | RMSE: 3703495.75\nEpoch 199 | Train Loss: 308977.4783 | Val Loss: 310086.2012 | RMSE: 3716102.25\nEpoch 200 | Train Loss: 307667.3542 | Val Loss: 302064.2158 | RMSE: 3756657.50 | R2: 0.5293\nEpoch 201 | Train Loss: 306987.3746 | Val Loss: 304743.4898 | RMSE: 3699717.50\nEpoch 202 | Train Loss: 307550.0130 | Val Loss: 304278.6191 | RMSE: 3717954.00\nEpoch 203 | Train Loss: 306407.2267 | Val Loss: 303107.9422 | RMSE: 3730432.50\nEpoch 204 | Train Loss: 306484.1238 | Val Loss: 299058.0782 | RMSE: 3698154.75\nEpoch 205 | Train Loss: 305397.1606 | Val Loss: 302728.6680 | RMSE: 3708406.00 | R2: 0.5413\nEpoch 206 | Train Loss: 306903.3381 | Val Loss: 310958.1445 | RMSE: 3710092.50\nEpoch 207 | Train Loss: 306102.7301 | Val Loss: 299821.9387 | RMSE: 3710109.25\nEpoch 208 | Train Loss: 305065.5141 | Val Loss: 307096.8516 | RMSE: 3735034.50\nEpoch 209 | Train Loss: 304770.9156 | Val Loss: 306407.1636 | RMSE: 3727751.50\nEpoch 210 | Train Loss: 304229.3835 | Val Loss: 304631.7069 | RMSE: 3709810.50 | R2: 0.5409\nEpoch 211 | Train Loss: 303666.8823 | Val Loss: 301771.1206 | RMSE: 3701997.25\nEpoch 212 | Train Loss: 303913.5908 | Val Loss: 312938.7080 | RMSE: 3700305.50\nEpoch 213 | Train Loss: 303057.7531 | Val Loss: 299812.2173 | RMSE: 3679032.25\nEpoch 214 | Train Loss: 302642.1686 | Val Loss: 300601.9000 | RMSE: 3705613.00\nEpoch 215 | Train Loss: 302758.8240 | Val Loss: 308207.0702 | RMSE: 3671610.75 | R2: 0.5503\nEpoch 216 | Train Loss: 301581.8959 | Val Loss: 304224.1198 | RMSE: 3669868.25\nEpoch 217 | Train Loss: 301726.3215 | Val Loss: 304764.0154 | RMSE: 3704153.00\nEpoch 218 | Train Loss: 301223.8691 | Val Loss: 301518.3318 | RMSE: 3683101.50\nEpoch 219 | Train Loss: 300910.0663 | Val Loss: 305921.8724 | RMSE: 3691680.75\nEpoch 220 | Train Loss: 300480.4519 | Val Loss: 307807.3844 | RMSE: 3690773.75 | R2: 0.5456\nEpoch 221 | Train Loss: 300888.6924 | Val Loss: 299790.2157 | RMSE: 3687051.25\nEpoch 222 | Train Loss: 299653.0811 | Val Loss: 305639.8599 | RMSE: 3673308.25\nEpoch 223 | Train Loss: 301023.8668 | Val Loss: 306264.9093 | RMSE: 3665225.50\nEpoch 224 | Train Loss: 300296.7743 | Val Loss: 313599.9684 | RMSE: 3684181.50\nEpoch 225 | Train Loss: 300603.0321 | Val Loss: 306903.2695 | RMSE: 3686618.00 | R2: 0.5467\nEpoch 226 | Train Loss: 299308.6422 | Val Loss: 307857.9390 | RMSE: 3689493.50\nEpoch 227 | Train Loss: 299596.4656 | Val Loss: 306234.9063 | RMSE: 3699778.25\nEpoch 228 | Train Loss: 299329.3958 | Val Loss: 302610.0697 | RMSE: 3704859.00\nEpoch 229 | Train Loss: 297756.5516 | Val Loss: 310912.2522 | RMSE: 3692152.50\nEpoch 230 | Train Loss: 297951.4055 | Val Loss: 310515.1276 | RMSE: 3685979.50 | R2: 0.5468\nEpoch 231 | Train Loss: 297554.9620 | Val Loss: 309154.1444 | RMSE: 3669251.00\nEpoch 232 | Train Loss: 297957.6068 | Val Loss: 309503.1002 | RMSE: 3689521.00\nEpoch 233 | Train Loss: 297253.5952 | Val Loss: 306397.1488 | RMSE: 3698709.50\nEpoch 234 | Train Loss: 296424.3183 | Val Loss: 309582.6716 | RMSE: 3700179.00\nEpoch 235 | Train Loss: 297583.2626 | Val Loss: 310755.9609 | RMSE: 3671837.75 | R2: 0.5503\nEpoch 236 | Train Loss: 296315.8285 | Val Loss: 316008.1514 | RMSE: 3671047.50\nEpoch 237 | Train Loss: 296570.9291 | Val Loss: 318441.6642 | RMSE: 3672513.00\nEpoch 238 | Train Loss: 296474.8192 | Val Loss: 315551.6496 | RMSE: 3667928.50\nEpoch 239 | Train Loss: 295752.1570 | Val Loss: 312021.1626 | RMSE: 3672515.25\nEpoch 240 | Train Loss: 295809.3218 | Val Loss: 319287.3460 | RMSE: 3662581.50 | R2: 0.5526\nEpoch 241 | Train Loss: 294435.6670 | Val Loss: 315184.9488 | RMSE: 3673870.00\nEpoch 242 | Train Loss: 295180.4049 | Val Loss: 318295.9388 | RMSE: 3685375.25\nEpoch 243 | Train Loss: 294507.0356 | Val Loss: 320462.6088 | RMSE: 3684196.00\nEpoch 244 | Train Loss: 295106.6514 | Val Loss: 316720.5444 | RMSE: 3667846.75\nEpoch 245 | Train Loss: 295202.3921 | Val Loss: 317184.2139 | RMSE: 3688087.00 | R2: 0.5463\nEpoch 246 | Train Loss: 294036.0123 | Val Loss: 315494.2085 | RMSE: 3687353.50\nEpoch 247 | Train Loss: 293933.0233 | Val Loss: 317891.0993 | RMSE: 3680869.25\nEpoch 248 | Train Loss: 293403.5236 | Val Loss: 319149.7152 | RMSE: 3669780.50\nEpoch 249 | Train Loss: 293583.1958 | Val Loss: 318319.5897 | RMSE: 3670784.00\nEpoch 250 | Train Loss: 293465.5476 | Val Loss: 316046.3380 | RMSE: 3688619.25 | R2: 0.5462\nEpoch 251 | Train Loss: 293423.1681 | Val Loss: 317250.8870 | RMSE: 3652674.25\nEpoch 252 | Train Loss: 293491.7511 | Val Loss: 313403.6954 | RMSE: 3678872.25\nEpoch 253 | Train Loss: 293127.3227 | Val Loss: 323943.2225 | RMSE: 3690474.00\nEpoch 254 | Train Loss: 292657.8752 | Val Loss: 322357.8741 | RMSE: 3680832.25\nEpoch 255 | Train Loss: 292478.2494 | Val Loss: 317728.8260 | RMSE: 3679488.25 | R2: 0.5484\nEpoch 256 | Train Loss: 291982.2643 | Val Loss: 314514.9850 | RMSE: 3679767.00\nEpoch 257 | Train Loss: 292652.4267 | Val Loss: 322609.3969 | RMSE: 3684359.75\nEpoch 258 | Train Loss: 292598.1005 | Val Loss: 319817.6168 | RMSE: 3684972.50\nEpoch 259 | Train Loss: 293570.9984 | Val Loss: 322378.3963 | RMSE: 3677978.25\nEpoch 260 | Train Loss: 291917.5828 | Val Loss: 320003.8035 | RMSE: 3680963.75 | R2: 0.5481\nEpoch 261 | Train Loss: 291560.7545 | Val Loss: 321459.8575 | RMSE: 3679251.00\nEpoch 262 | Train Loss: 291979.2940 | Val Loss: 323070.2641 | RMSE: 3686407.00\nEpoch 263 | Train Loss: 291897.0707 | Val Loss: 320989.7759 | RMSE: 3681788.50\nEpoch 264 | Train Loss: 290717.4093 | Val Loss: 324558.7308 | RMSE: 3682599.00\nEpoch 265 | Train Loss: 291272.1231 | Val Loss: 326624.5554 | RMSE: 3682375.25 | R2: 0.5477\nEpoch 266 | Train Loss: 290892.2537 | Val Loss: 322747.9356 | RMSE: 3683196.50\nEpoch 267 | Train Loss: 290777.9265 | Val Loss: 323746.4965 | RMSE: 3683180.75\nEpoch 268 | Train Loss: 290791.0228 | Val Loss: 325989.4820 | RMSE: 3683809.00\nEpoch 269 | Train Loss: 290398.0886 | Val Loss: 326293.4972 | RMSE: 3671495.75\nEpoch 270 | Train Loss: 290393.0909 | Val Loss: 320460.7075 | RMSE: 3682381.25 | R2: 0.5477\nEpoch 271 | Train Loss: 289791.7791 | Val Loss: 319882.5068 | RMSE: 3681475.25\nEpoch 272 | Train Loss: 290388.0699 | Val Loss: 320505.0730 | RMSE: 3682812.75\nEpoch 273 | Train Loss: 289935.8654 | Val Loss: 320449.1303 | RMSE: 3681653.00\nEpoch 274 | Train Loss: 290656.8724 | Val Loss: 324763.3584 | RMSE: 3680997.00\nEpoch 275 | Train Loss: 290194.2222 | Val Loss: 323272.8906 | RMSE: 3682250.00 | R2: 0.5477\nEpoch 276 | Train Loss: 290012.9851 | Val Loss: 323612.3451 | RMSE: 3681934.25\nEpoch 277 | Train Loss: 289384.0707 | Val Loss: 320962.7257 | RMSE: 3681310.75\nEpoch 278 | Train Loss: 290053.2810 | Val Loss: 323718.0533 | RMSE: 3685342.50\nEpoch 279 | Train Loss: 290540.8247 | Val Loss: 321438.3981 | RMSE: 3680785.50\nEpoch 280 | Train Loss: 289795.4956 | Val Loss: 323227.0005 | RMSE: 3680033.00 | R2: 0.5483\nEpoch 281 | Train Loss: 289580.8024 | Val Loss: 323600.3281 | RMSE: 3679787.25\nEpoch 282 | Train Loss: 290254.6636 | Val Loss: 323016.3876 | RMSE: 3679884.00\nEpoch 283 | Train Loss: 290374.5784 | Val Loss: 324051.0862 | RMSE: 3679667.50\nEpoch 284 | Train Loss: 289714.9672 | Val Loss: 322878.3842 | RMSE: 3681852.25\nEpoch 285 | Train Loss: 289973.3534 | Val Loss: 322968.0416 | RMSE: 3680226.25 | R2: 0.5482\nEpoch 286 | Train Loss: 289670.7711 | Val Loss: 323705.7822 | RMSE: 3681039.25\nEpoch 287 | Train Loss: 288954.7130 | Val Loss: 321426.4857 | RMSE: 3682060.50\nEpoch 288 | Train Loss: 289159.1214 | Val Loss: 322592.5233 | RMSE: 3680094.00\nEpoch 289 | Train Loss: 289631.5608 | Val Loss: 322596.0307 | RMSE: 3681625.00\nEpoch 290 | Train Loss: 289061.5185 | Val Loss: 322399.6883 | RMSE: 3681683.75 | R2: 0.5479\nEpoch 291 | Train Loss: 289684.1874 | Val Loss: 323011.9725 | RMSE: 3683453.75\nEpoch 292 | Train Loss: 289177.5333 | Val Loss: 323577.5305 | RMSE: 3682988.50\nEpoch 293 | Train Loss: 289013.6570 | Val Loss: 322942.0812 | RMSE: 3683057.75\nEpoch 294 | Train Loss: 289551.4081 | Val Loss: 323314.4131 | RMSE: 3683146.75\nEpoch 295 | Train Loss: 288833.3425 | Val Loss: 323381.1366 | RMSE: 3683358.00 | R2: 0.5475\nEpoch 296 | Train Loss: 288885.6888 | Val Loss: 323655.2572 | RMSE: 3683269.75\nEpoch 297 | Train Loss: 289499.1065 | Val Loss: 323579.6763 | RMSE: 3683075.75\nEpoch 298 | Train Loss: 288949.3645 | Val Loss: 323403.2737 | RMSE: 3683031.50\nEpoch 299 | Train Loss: 288837.7419 | Val Loss: 323254.5813 | RMSE: 3683017.75\nEpoch 300 | Train Loss: 289404.0855 | Val Loss: 323311.5694 | RMSE: 3683007.50 | R2: 0.5476\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"### Визуализация кривых обучения  \nСтроим график изменения лосса на обучении и валидации по эпохам.","metadata":{}},{"cell_type":"code","source":"epochs = [x for x in range(1, 301)]\nval_losses = [2787061.4696, 2740000.5028, 2667585.7444, 2573787.0579, 2481351.6412, 2410079.0547, 2327036.2037, 2213476.1585, 2079783.4428, 1931696.7157, 1774706.5318, 1607108.2052, 1443726.3459, 1293794.0946, 1163006.2272, 1051960.3683, 963693.5435, 886156.9236, 818776.3621, 771194.6112, 722162.701, 675421.7182, 644965.0819, 618589.0576, 590625.4669, 564061.8678, 567547.5614, 524233.2545, 512921.705, 486817.1366, 477857.2245, 456281.1898, 451250.1415, 437052.8832, 431081.9141, 427537.2441, 420148.7396, 418725.8763, 405220.7251, 408763.1347, 402879.6759, 395595.9316, 397568.6195, 389308.468, 381775.4267, 383048.1619, 381286.4624, 377380.6873, 376008.5831, 376024.3226, 367218.7576, 363726.4507, 365849.3581, 360532.8241, 359451.7271, 364507.6093, 364033.1679, 358096.8113, 356937.5077, 359072.3169, 365585.2222, 357251.4375, 354403.2899, 348284.8285, 353764.0855, 349279.8118, 355860.2391, 354477.7352, 345870.0618, 346553.0441, 336562.1287, 341053.7825, 352003.6595, 335804.9691, 336250.8623, 339860.5465, 334971.182, 333313.9188, 343162.9675, 334032.6657, 331372.5128, 331203.1292, 327251.7406, 342334.7028, 331994.9577, 323416.059, 325607.9578, 325798.9734, 325786.2664, 323567.1781, 329512.259, 331566.1613, 327022.0424, 321176.264, 320452.395, 317330.0192, 320171.3803, 322471.7036, 319116.6659, 321824.2962, 315233.8256, 318297.6498, 321149.4061, 321979.9661, 311658.1076, 311975.6092, 312505.8525, 316528.7414, 320266.2142, 323631.9505, 324987.7777, 310301.3137, 313183.5262, 312002.9324, 310071.5685, 312903.2934, 311215.0127, 309669.783, 320603.1944, 310007.1198, 313529.4193, 310291.0711, 309631.5249, 310806.1233, 317087.8669, 307048.618, 309243.2733, 305107.6489, 312952.8324, 308840.2042, 311760.598, 313632.9651, 305817.7242, 309076.8928, 306006.8992, 310891.9696, 305314.3804, 305822.9176, 301739.2191, 305539.5524, 302568.1806, 309648.5617, 302120.408, 302196.4026, 303814.9488, 308361.7826, 302431.9366, 296940.3568, 305820.7092, 312088.7853, 302509.9972, 307109.847, 308564.1374, 304308.5627, 309521.2331, 305690.1976, 302548.9443, 296930.093, 302640.899, 295959.7905, 297225.67, 299348.4523, 300231.1423, 307116.403, 296179.3037, 304028.1248, 302420.2965, 298689.2353, 296602.9791, 296023.9567, 299129.8927, 301494.1065, 299458.829, 303256.6089, 300815.322, 292787.2294, 295202.8082, 303307.3264, 297473.6981, 298951.1841, 299892.0614, 300685.4197, 299268.7714, 298899.3403, 304213.2207, 304246.8279, 294027.1277, 301463.9665, 304047.0477, 299389.2036, 300816.4365, 299621.6779, 308107.6956, 303383.2142, 300817.2382, 306566.2873, 305678.3793, 312148.1812, 310086.2012, 302064.2158, 304743.4898, 304278.6191, 303107.9422, 299058.0782, 302728.668, 310958.1445, 299821.9387, 307096.8516, 306407.1636, 304631.7069, 301771.1206, 312938.708, 299812.2173, 300601.9, 308207.0702, 304224.1198, 304764.0154, 301518.3318, 305921.8724, 307807.3844, 299790.2157, 305639.8599, 306264.9093, 313599.9684, 306903.2695, 307857.939, 306234.9063, 302610.0697, 310912.2522, 310515.1276, 309154.1444, 309503.1002, 306397.1488, 309582.6716, 310755.9609, 316008.1514, 318441.6642, 315551.6496, 312021.1626, 319287.346, 315184.9488, 318295.9388, 320462.6088, 316720.5444, 317184.2139, 315494.2085, 317891.0993, 319149.7152, 318319.5897, 316046.338, 317250.887, 313403.6954, 323943.2225, 322357.8741, 317728.826, 314514.985, 322609.3969, 319817.6168, 322378.3963, 320003.8035, 321459.8575, 323070.2641, 320989.7759, 324558.7308, 326624.5554, 322747.9356, 323746.4965, 325989.482, 326293.4972, 320460.7075, 319882.5068, 320505.073, 320449.1303, 324763.3584, 323272.8906, 323612.3451, 320962.7257, 323718.0533, 321438.3981, 323227.0005, 323600.3281, 323016.3876, 324051.0862, 322878.3842, 322968.0416, 323705.7822, 321426.4857, 322592.5233, 322596.0307, 322399.6883, 323011.9725, 323577.5305, 322942.0812, 323314.4131, 323381.1366, 323655.2572, 323579.6763, 323403.2737, 323254.5813, 323311.5694]\ntrain_losses = [2801163.1415, 2768886.6004, 2708672.4371, 2625183.8004, 2526684.1674, 2448096.8063, 2374717.6262, 2276728.599, 2152229.363, 2012676.0252, 1858437.2074, 1697453.0607, 1531469.8197, 1377300.1798, 1238086.1908, 1121155.8037, 1025346.9096, 946339.9176, 878757.0762, 823240.9286, 779296.4449, 729189.7989, 692321.2767, 662169.5451, 635844.5796, 612771.4867, 591006.6584, 570748.0699, 552393.3104, 537668.2525, 519915.0617, 504566.5305, 490801.8513, 480924.6456, 470674.8805, 463028.1573, 457131.6399, 452123.1577, 447648.6668, 443632.4814, 439911.6259, 436431.5096, 433692.1732, 431060.8523, 428517.3941, 423456.383, 420914.0706, 416390.3487, 411865.3583, 411903.4718, 408777.1514, 404907.4064, 402601.5923, 400023.7384, 398448.4867, 396920.5998, 395039.2224, 393940.1693, 393791.6001, 392781.7952, 391983.7251, 389912.3581, 388524.1042, 386531.7817, 385335.7642, 384502.8699, 383248.6651, 381222.9709, 380163.7862, 380186.8059, 376874.2897, 376455.0875, 377150.9199, 375165.3322, 376034.1861, 373655.3431, 373039.6689, 371816.4822, 368497.6912, 368598.4856, 369728.2589, 367952.5767, 366354.0299, 365002.3664, 365368.5545, 364536.5109, 362942.8861, 363448.7423, 361636.053, 359863.4811, 361421.294, 359786.5843, 359110.2688, 357651.261, 357608.4518, 354777.6881, 355468.9278, 355990.5961, 355356.0399, 353791.7122, 352570.3007, 354080.363, 354095.1659, 353167.8334, 350352.5015, 350748.0879, 352301.8312, 350304.9837, 350415.7906, 347941.3421, 347979.273, 346448.0831, 346562.9324, 345911.6457, 344472.1962, 345285.9893, 343190.4574, 344410.1681, 343973.716, 341304.1385, 341885.0995, 341578.0578, 340763.9611, 339732.5207, 340374.0601, 338939.1268, 338617.0749, 338518.4333, 336518.9019, 337923.7167, 335949.8082, 338241.7068, 336121.7495, 335785.1716, 334303.0239, 335193.8443, 334308.0206, 333228.8974, 331515.87, 331897.4282, 331773.167, 330378.7094, 329110.3207, 329938.8638, 329557.7093, 328065.1225, 328337.6424, 329058.2702, 327123.3125, 327205.9531, 328058.4557, 326889.9653, 325699.8032, 325706.6745, 325480.5003, 325575.7467, 325141.7869, 324276.4635, 323458.1285, 324947.6232, 324934.2234, 322695.9059, 322549.4814, 323102.8953, 321620.7574, 322553.7414, 321972.8149, 322734.5349, 321106.3927, 320736.4065, 318902.3194, 320534.7034, 319739.7137, 317871.0896, 317073.277, 316606.2111, 316028.8499, 315419.0741, 313797.2952, 315281.2386, 314639.7057, 313507.2386, 312652.3946, 313502.884, 312265.1585, 312682.712, 313004.241, 310940.5559, 312179.2274, 311483.0115, 310527.2154, 310465.3204, 310103.3335, 310279.4856, 309640.3631, 309268.1015, 308601.2944, 307901.8065, 308977.4783, 307667.3542, 306987.3746, 307550.013, 306407.2267, 306484.1238, 305397.1606, 306903.3381, 306102.7301, 305065.5141, 304770.9156, 304229.3835, 303666.8823, 303913.5908, 303057.7531, 302642.1686, 302758.824, 301581.8959, 301726.3215, 301223.8691, 300910.0663, 300480.4519, 300888.6924, 299653.0811, 301023.8668, 300296.7743, 300603.0321, 299308.6422, 299596.4656, 299329.3958, 297756.5516, 297951.4055, 297554.962, 297957.6068, 297253.5952, 296424.3183, 297583.2626, 296315.8285, 296570.9291, 296474.8192, 295752.157, 295809.3218, 294435.667, 295180.4049, 294507.0356, 295106.6514, 295202.3921, 294036.0123, 293933.0233, 293403.5236, 293583.1958, 293465.5476, 293423.1681, 293491.7511, 293127.3227, 292657.8752, 292478.2494, 291982.2643, 292652.4267, 292598.1005, 293570.9984, 291917.5828, 291560.7545, 291979.294, 291897.0707, 290717.4093, 291272.1231, 290892.2537, 290777.9265, 290791.0228, 290398.0886, 290393.0909, 289791.7791, 290388.0699, 289935.8654, 290656.8724, 290194.2222, 290012.9851, 289384.0707, 290053.281, 290540.8247, 289795.4956, 289580.8024, 290254.6636, 290374.5784, 289714.9672, 289973.3534, 289670.7711, 288954.713, 289159.1214, 289631.5608, 289061.5185, 289684.1874, 289177.5333, 289013.657, 289551.4081, 288833.3425, 288885.6888, 289499.1065, 288949.3645, 288837.7419, 289404.0855]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T13:49:48.461723Z","iopub.execute_input":"2025-06-15T13:49:48.462426Z","iopub.status.idle":"2025-06-15T13:49:48.481073Z","shell.execute_reply.started":"2025-06-15T13:49:48.462401Z","shell.execute_reply":"2025-06-15T13:49:48.480277Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.plot(epochs, train_losses, label='Train Loss')\nplt.plot(epochs, val_losses,   label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Кривые обучения и валидации')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T13:49:59.043489Z","iopub.execute_input":"2025-06-15T13:49:59.043997Z","iopub.status.idle":"2025-06-15T13:49:59.324469Z","shell.execute_reply.started":"2025-06-15T13:49:59.043973Z","shell.execute_reply":"2025-06-15T13:49:59.323745Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## Выводы по кривым обучения и валидации\n\n1. **Быстрое снижение в начале**  \n   В первые ~30–40 эпох происходит резкий спад как тренировочного, так и валидационного loss — модель сразу захватывает основные закономерности.\n\n2. **Плато и стабилизация**  \n   После ~100 эпох кривые практически выровнялись и продолжают очень медленно снижаться, что говорит о приближении к локальному минимуму.\n\n3. **Возможность сокращения числа эпох**  \n   Поскольку после ~150-200 эпох улучшения минимальны(даже наоборот начинают проявляться признаки переобучения), можно сократить обучение.\n\n4. **Итоговая ошибка**  \n   Окончательный уровень loss ≈ 3 × 10⁵ на обоих наборах и $R^2$≈0.55 на тесте.\n","metadata":{}}]}